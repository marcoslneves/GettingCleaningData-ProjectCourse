{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Getting and Cleaning Data - Course Project\"\nauthor: \"Marcos Neves\"\ndate: \"12/11/2016\"\noutput: html_document\n---\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n```\n\n### Description of the project\nThe project was designed to generate a single and tidy dataset made from a data cleaning process performed on 8 datasets downloaded from <http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones>. The goal is to have a single file ready to perform Exploratory Analysis\n\nThe tidy data obtained has been made merging de training and test datasets and using the others datasets to get more descriptive activity labels and column names.\n\nAll the datasets can be found here: \n<https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip>\n\n\n### Data Source Information\n\n***Abstract:*** Human Activity Recognition database built from the recordings of 30 subjects performing activities of daily living (ADL) while carrying a waist-mounted smartphone with embedded inertial sensors.\n\nThe experiments have been carried out with a group of age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. \n\nA full description of the data used in this project can be found in <http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones>\n\n### Data transformation\n\nThe process was performed using the file run_analisys.R to do all the steps below to download, merge, clean and create the final single tidy dataset.\n\n### Process steps \n\n\n##### 1 - Download and read the raw datasets\n\n```{r}\n## Loading required libraries \nlibrary(dplyr)\n\nif(!file.exists(\"./data\")){\n    dir.create(\"./data\")\n}\n\nzip_path <- \"./data/UCI_HAR_Dataset.zip\"\nfile_url <- \"https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip\"\n\nif (!file.exists(zip_path)){\n    download.file(file_url, destfile=zip_path, method=\"curl\")\n} \n\nif (!file.exists(\"UCI HAR Dataset\")) { \n    ## unzip the file\n    unzip(zipfile=zip_path, exdir=\"./data\")\n}\n\n## Read Features names\ndata_features_names <- tbl_df(read.table(file = \"data/UCI HAR Dataset/features.txt\"))\n\n##Read data values for Features \ndata_features_train <- tbl_df(read.table(file = \"data/UCI HAR Dataset/train/X_train.txt\"))\ndata_features_test <- tbl_df(read.table(file = \"data/UCI HAR Dataset/test/X_test.txt\"))\n\n##Read data values for Activity values and labels\ndata_activity_train <- tbl_df(read.table(file = \"data/UCI HAR Dataset/train/Y_train.txt\"))\ndata_activity_test <- tbl_df(read.table(file = \"data/UCI HAR Dataset/test/Y_test.txt\"))\ndata_activity_labels <- tbl_df(read.table(file = \"data/UCI HAR Dataset/activity_labels.txt\"))\n\n##Read data values for Subject Identifier ( Who)\ndata_subject_train <- tbl_df(read.table(file = \"data/UCI HAR Dataset/train/subject_train.txt\"))\ndata_subject_test <- tbl_df(read.table(file = \"data/UCI HAR Dataset/test/subject_test.txt\"))\n\n\n```\n\n\n##### 2 - Merges train and test datasets\n\nTest and training data (X_train.txt, X_test.txt), subject ids (subject_train.txt,\nsubject_test.txt) and activity ids (y_train.txt, y_test.txt) are merged to obtain\na single data set. Variables are labelled with the names assigned by original\ncollectors (features.txt).\n\n```{r}\n## Merging the Features train and test datasets\ndata_features <- rbind(data_features_train, data_features_test)\n## Assign a vector of names from data_features_names to variable names(colnames) in data_features to have more descriptive names for each Feature\nnames(data_features) = data_features_names$V2\n\n## Merging the Activity train and test datasets and merges the result dataset with the Activity Labels dataset to get more descriptive labels  \ndata_activity <- rbind(data_activity_train, data_activity_test)\ndata_activity <- merge(data_activity, data_activity_labels, by = \"V1\")\ndata_activity$V1 <- NULL\nnames(data_activity) = \"activity\"\n\n## Merging the train and test Subject identifier data\ndata_subject <- rbind(data_subject_train, data_subject_test)\nnames(data_subject) = \"subject\"\n\n\n```\n##### 3 - Extract only the mean and standard deviation measurements from data_features\n```{r}\n## Filtering by mean() and std() measurements for each Feature\ndata_features_filtered <- data_features[, grepl(\"mean\\\\(\\\\)|std\\\\(\\\\)\", names(data_features))]\nstr(data_features_filtered)\n```\n\n\n##### 4 - Merging the Features, Activity and Subject datasets \n```{r}\ndata_all_clean <- tbl_df(cbind(data_subject, data_activity, data_features_filtered))\n```\n\n##### Clean and label variables appropriately\nLabels given from the original collectors were changed:\n* to obtain valid R names without parentheses, dashes and commas\n* to obtain more descriptive labels\n```{r}\nnames_vec <- names(data_all_clean)\nnames_vec <- gsub(\"\\\\(\", \"\", names_vec)\nnames_vec <- gsub(\"\\\\)\", \"\", names_vec)\nnames_vec <- gsub(\"\\\\-\", \"_\", names_vec)\nnames_vec <- gsub(\",\", \"_\", names_vec)\nnames_vec <- gsub(\"^t\", \"time\", names_vec)\nnames_vec <- gsub(\"^f\", \"frequency\", names_vec)\nnames_vec <- gsub(\"Acc\", \"Acceleration\", names_vec)\nnames_vec <- gsub(\"Gyro\", \"Gyroscope\", names_vec)\nnames_vec <- gsub(\"Mag\", \"Magnitude\", names_vec)\nnames_vec <- gsub(\"BodyBody\", \"Body\", names_vec)\nnames_vec <- gsub(\"mean\", \"Mean\", names_vec)\nnames_vec <- gsub(\"std\", \"StandardDeviation\", names_vec)\nnames(data_all_clean) <- names_vec\n\n\n```\n\n\n#### Create a tidy data set\nCreated a single final tidy dataset from the intermediate dataset \nAll the variables variables are averaged for each activity and each subject\n\nThe tidy data set contains 10299 observations with 68 variables divided in:\n\n*  identifier for the __subject__ who carried out the experiment (variable __subject__ | integer 1:30):\n*  activity label (__activity__): WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING\n*  a 66-feature vector of means with time and frequency variables (numeric and normalized)\n\n```{r}\n## Aggregate all the Features measurements by Activity and Subject\ndata_tidy <- aggregate(. ~ subject + activity, data_all_clean, mean)\ndata_tidy <- arrange(data_tidy, subject, activity)\n\n## Write to txt file\nwrite.table(data_tidy, './data/UCI_HAR_tidy_data.txt', row.names=TRUE)\n\ndim(data_all_clean)\nhead(data_all_clean)\n\n\n```\n\nThe final processed tidy data can be found at  __./data/UCI_HAR_tidy_data.txt__\n\n\n\n",
    "created" : 1481631967350.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3752764839",
    "id" : "8DDD4BE4",
    "lastKnownWriteTime" : 1481632020,
    "last_content_update" : 1481632020065,
    "path" : "/Volumes/MNevesHD/Dev/R/Coursera course/datasciencecoursera/GettingCleaningData-ProjectCourse/CodeBook.Rmd",
    "project_path" : "CodeBook.Rmd",
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}